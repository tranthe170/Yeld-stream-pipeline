version: "3"
services:
  minio:
    image: minio/minio
    container_name: minio
    ports:
      - "9001:9001"
      - "9000:9000"
    command: ["server", "/data", "--console-address", ":9001"]
    volumes:
      - ./mnt/minio_data:/data
    environment:
      MINIO_ROOT_USER: "minio"
      MINIO_ROOT_PASSWORD: "minio123"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - data_network

  mc:
    depends_on:
      - minio
    image: minio/mc
    environment:
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
    entrypoint: >
      /bin/sh -c "
      until (/usr/bin/mc config host add minio http://minio:9000 minio minio123) do echo '...waiting...' && sleep 1; done;

      if /usr/bin/mc ls minio/warehouse > /dev/null 2>&1; then
        echo 'Bucket warehouse exists, skipping removal.';
      else
        echo 'Bucket warehouse does not exist, creating it.';
        /usr/bin/mc mb minio/warehouse;
        /usr/bin/mc policy set public minio/warehouse;
      fi;

      tail -f /dev/null
      "
    networks:
      - data_network

  mysql:
    image: mariadb:10.5.16
    container_name: mysql
    volumes:
      - ./mnt/mysql_data:/var/lib/mysql
    ports:
      - "3306:3306"
    environment:
      MYSQL_ROOT_PASSWORD: admin
      MYSQL_DATABASE: metastore_db
      MYSQL_USER: admin
      MYSQL_PASSWORD: admin
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - data_network

  hive-metastore:
    build: ./docker/hive-metastore
    container_name: hive-metastore
    depends_on:
      - mysql
    volumes:
      - ./docker/hive-metastore/metastore-site.xml:/opt/hive/conf/metastore-site.xml
      - ./mnt/hive_warehouse:/mnt/hive/warehouse
    ports:
      - "9083:9083"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9083"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - data_network

  spark-master:
    build: ./docker/spark/spark-master
    restart: always
    container_name: spark-master
    ports:
      - "8082:8082"
      - "7077:7077"
    volumes:
      - ./mnt/spark_apps:/opt/spark-apps
      - ./mnt/spark_data:/opt/spark-data
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "8082"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - data_network

  spark-worker:
    build: ./docker/spark/spark-worker
    container_name: spark-worker
    depends_on:
      - spark-master
    ports:
      - "8083:8083"
    volumes:
      - ./mnt/spark_apps:/opt/spark-apps
      - ./mnt/spark_data:/opt/spark-data
    environment:
      SPARK_MASTER: "spark://spark-master:7077"
      SPARK_WORKER_CORES: 4
      SPARK_WORKER_MEMORY: 2G
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "8083"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - data_network

  jupyter-notebook:
    build: ./docker/jupyter
    container_name: jupyter-notebook
    ports:
      - "8888:8888"
    volumes:
      - ./mnt/notebooks:/opt/notebooks
    environment:
      SPARK_MASTER: "spark://spark-master:7077"
    networks:
      - data_network
    depends_on:
      - spark-master
      - spark-worker

  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.2
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zookeeper:2888:3888
    networks:
      - data_network

  kafka:
    image: confluentinc/cp-kafka:7.3.2
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:19092,EXTERNAL://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
    depends_on:
      - zookeeper
    networks:
      - data_network

  kafka-schema-registry:
    image: confluentinc/cp-schema-registry:7.3.2
    hostname: kafka-schema-registry
    container_name: kafka-schema-registry
    depends_on:
      - zookeeper
      - kafka
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: kafka-schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "PLAINTEXT://kafka:19092"
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    networks:
      - data_network

  postgresql:
    image: postgres:14
    hostname: postgresql
    container_name: postgresql
    volumes:
      - ./mnt/pg_data:/var/lib/postgresql/data
    environment:
      POSTGRES_DB: "conduktor-platform"
      POSTGRES_USER: "conduktor"
      POSTGRES_PASSWORD: "some_password"
      POSTGRES_HOST_AUTH_METHOD: "scram-sha-256"
    networks:
      - data_network

  conduktor-platform:
    image: conduktor/conduktor-platform:latest
    hostname: conduktor-platform
    container_name: conduktor-platform
    ports:
      - "8080:8080"
    volumes:
      - ./mnt/conduktor_data:/var/conduktor
    environment:
      CDK_ORGANIZATION_NAME: "demo"
      CDK_ADMIN_EMAIL: "admin@admin.io"
      CDK_ADMIN_PASSWORD: "admin"
      CDK_DATABASE_URL: "postgresql://conduktor:some_password@postgresql:5432/conduktor-platform"
      CDK_CLUSTERS_0_ID: "default"
      CDK_CLUSTERS_0_NAME: "My Local Kafka Cluster"
      CDK_CLUSTERS_0_COLOR: "#0013E7"
      CDK_CLUSTERS_0_BOOTSTRAPSERVERS: "PLAINTEXT://kafka:19092"
      CDK_CLUSTERS_0_SCHEMAREGISTRY_URL: "http://kafka-schema-registry:8081"
      CDK_CLUSTERS_0_KAFKACONNECTS_0_URL: "http://kafka-connect:8088"
      CDK_CLUSTERS_0_KAFKACONNECTS_0_NAME: "full stack kafka connect"
    depends_on:
      - postgresql
      - kafka-schema-registry
    networks:
      - data_network

  producer:
    build: ./docker/producer
    container_name: kafka-producer
    depends_on:
      - kafka
    volumes:
      - ./data:/app/data
    environment:
      - KAFKA_BROKER=kafka:9092
    networks:
      - data_network

  trino-coordinator:
    build: ./docker/trino
    container_name: trino-coordinator
    environment:
      - TRINO_NODE_ID=coordinator
    volumes:
      - ./mnt/trino/data:/opt/trino/data
      - ./docker/trino/etc/catalog/delta.properties:/opt/trino/server/etc/catalog/delta.properties
      - ./docker/trino/etc/node.properties:/opt/trino/server/etc/node.properties
      - ./docker/trino/etc/config.properties:/opt/trino/server/etc/config.properties
      - ./docker/trino/etc/jvm.config:/opt/trino/server/etc/jvm.config
    ports:
      - "8443:8443"
    networks:
      - data_network
    depends_on:
      - hive-metastore
    command: ["bin/launcher", "run"]

  trino-worker:
    build: ./docker/trino
    container_name: trino-worker
    environment:
      - TRINO_NODE_ID=worker
    volumes:
      - ./mnt/trino/data:/opt/trino/data
      - ./docker/trino/etc/catalog/delta.properties:/opt/trino/server/etc/catalog/delta.properties
      - ./docker/trino/etc/node.properties:/opt/trino/server/etc/node.properties
      - ./docker/trino/etc/config.properties:/opt/trino/server/etc/config.properties
      - ./docker/trino/etc/jvm.config:/opt/trino/server/etc/jvm.config
    networks:
      - data_network
    depends_on:
      - trino-coordinator
    command: ["bin/launcher", "run"]

  superset:
    build: ./docker/superset
    container_name: superset
    ports:
      - 8089:8089
    environment:
      SUPERSET_ENV: development
      SUPERSET_CONFIG_PATH: /app/pythonpath/superset_config.py
      PYTHONPATH: /app/pythonpath
    volumes:
      - ./docker/superset/superset_config.py:/app/pythonpath/superset_config.py
    depends_on:
      - postgres-superset
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8089/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 5
    networks:
      - data_network

  postgres-superset:
    image: postgres:13
    environment:
      POSTGRES_DB: superset
      POSTGRES_USER: superset
      POSTGRES_PASSWORD: superset
    volumes:
      - ./mnt/postgres-superset:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U superset"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - data_network

networks:
  data_network:
    driver: bridge

volumes:
  minio_data:
  mysql_data:
  hive_warehouse:
  spark_apps:
  spark_data:
  pg_data:
  conduktor_data:
  notebooks:
  postgres-superset:
